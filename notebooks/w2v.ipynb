{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tqdm\n",
    "import pymorphy2\n",
    "import logging\n",
    "import os\n",
    "from string import punctuation\n",
    "from nltk import TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm.auto import tqdm\n",
    "from sqlalchemy import create_engine\n",
    "from src.config import conn_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pymorphy2.opencorpora_dict.wrapper:Loading dictionaries from /Users/lev4/PycharmProjects/app-sberjobs/sberjobs-trainer/venv/lib/python3.8/site-packages/pymorphy2_dicts_ru/data\n",
      "INFO:pymorphy2.opencorpora_dict.wrapper:format: 2.4, revision: 417127, updated: 2020-10-11T15:05:51.070345\n"
     ]
    }
   ],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "logging.basicConfig(level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines(conn_string):\n",
    "    \"\"\"\n",
    "    Подключается к БД и выкачивает вакансии\n",
    "    \"\"\"\n",
    "    logging.info(\"Подгружаю данные из базы\")\n",
    "    engine = create_engine(conn_string)\n",
    "\n",
    "    df = pd.read_sql_table('vacancy', engine)\n",
    "    logging.info(df.head)\n",
    "    lines = df.vacdescription.tolist()\n",
    "    vacids = df.vacid.tolist()\n",
    "    return lines, vacids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_pipe(lines):\n",
    "    logging.info(\"Готовлю корпус\")\n",
    "    ru_stop_words = stopwords.words('russian')\n",
    "    lines_tok = [TreebankWordTokenizer().tokenize(x) for x in lines]\n",
    "    lines_tok = [[x for x in el if x not in punctuation] for el in lines_tok]\n",
    "    u_norm = [[morph.parse(x)[0][2] for x in el] for el in tqdm(lines_tok)]\n",
    "    u_norm = [[x for x in el if x not in ru_stop_words] for el in tqdm(u_norm)]\n",
    "    corpus = [' '.join(x) for x in u_norm]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def l2_norm(x):\n",
    "    return np.sqrt(np.sum(x ** 2))\n",
    "\n",
    "\n",
    "def div_norm(x):\n",
    "    norm_value = l2_norm(x)\n",
    "    if norm_value > 0:\n",
    "        return x * (1.0 / norm_value)\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vacancy_vectors(vacids, corpus):\n",
    "    \"\"\"\n",
    "    Получает вектора профилей пользователей из фасттекста\n",
    "    \"\"\"\n",
    "\n",
    "    from gensim.models import FastText\n",
    "    \n",
    "    vacancy_vectors = {}\n",
    "    logging.info(\"Подгружаем обученную модель FastText\")\n",
    "    fasttext_pth = os.path.join('..','wvmodel','cc.ru.300.bin')\n",
    "    fast_text = FastText.load_fasttext_format(fasttext_pth).wv\n",
    "    \n",
    "    logging.info(\"Собираем векторы предложений\")\n",
    "    for x in tqdm((vacids, corpus)):\n",
    "\n",
    "        text = x[1].split()\n",
    "        text.append('\\n')\n",
    "        matrix = np.zeros((300,), dtype = 'float32')\n",
    "\n",
    "        for word in text:\n",
    "            matrix += div_norm(fast_text.word_vec(word))\n",
    "\n",
    "        vacancy_vectors[x[0]] = matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_similarities(target_user, candidates):\n",
    "    \"\"\"Получает косинусные сходства сотрудника и кандидатов\"\"\"\n",
    "\n",
    "    tu_sims = {}\n",
    "    for vacid in vacids:\n",
    "        tu_sims[candidates] = cosine_similarity(\n",
    "            vacancy_vectors[vacid],\n",
    "            user_vectors\n",
    "        )[0][0]\n",
    "\n",
    "    return tu_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conn_string' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-93a6fd1e3e69>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mlines\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvacids\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_lines\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconn_string\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'conn_string' is not defined"
     ]
    }
   ],
   "source": [
    "lines, vacids = get_lines(conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lines' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-6980abacff20>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mcorpus\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtxt_pipe\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlines\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'lines' is not defined"
     ]
    }
   ],
   "source": [
    "corpus = txt_pipe(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with open(os.path.join('..','data','corpus.pkl'), 'wb') as f:\n",
    "#     pickle.dump(corpus, f)\n",
    "\n",
    "# with open(os.path.join('..','data','vacids.pkl'), 'wb') as f:\n",
    "#     pickle.dump(vacids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/vacids.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-14-92eb2f2afadb>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'..'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m'data'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m'vacids.pkl'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'rb'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m     \u001B[0mvacids\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpickle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'..'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m'data'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m'corpus.pkl'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'rb'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mcorpus\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpickle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../data/vacids.pkl'"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('..','data','vacids.pkl'), 'rb') as f:\n",
    "    vacids = pickle.load(f)\n",
    "\n",
    "with open(os.path.join('..','data','corpus.pkl'), 'rb') as f:\n",
    "    corpus = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vvect = get_vacancy_vectors(vacids, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.info(\"Подгружаем обученную модель FastText\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models._fasttext_bin:loading 977837 words for fastText model from ../wvmodel/ft_native_300_ru_wiki_lenta_lemmatize.bin\n",
      "INFO:gensim.models.word2vec:resetting layer weights\n",
      "INFO:gensim.models.word2vec:Updating model with new vocabulary\n",
      "INFO:gensim.models.word2vec:New added 977837 unique words (50% of original 1955674) and increased the count of 977837 pre-existing words (50% of original 1955674)\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 977837 items\n",
      "INFO:gensim.models.word2vec:sample=0.0001 downsamples 788 most-common words\n",
      "INFO:gensim.models.word2vec:downsampling leaves estimated 830512760 word corpus (120.7% of prior 688220651)\n",
      "INFO:gensim.models.fasttext:loaded (2977837, 300) weight matrix for fastText model from ../wvmodel/ft_native_300_ru_wiki_lenta_lemmatize.bin\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import fasttext\n",
    "fasttext_pth = os.path.join('..','wvmodel','ft_native_300_ru_wiki_lenta_lemmatize.bin')\n",
    "fast_text = fasttext.load_facebook_vectors(fasttext_pth)\n",
    "\n",
    "# with open(os.path.join('..','data','fast_text.pkl'), 'rb') as f:\n",
    "#     fast_text = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# with open(os.path.join('..','data','fast_text.pkl'), 'wb') as f:\n",
    "#     pickle.dump(fast_text, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacancy_vectors = {}\n",
    "for x in tqdm(list(zip(vacids, corpus))):\n",
    "    text = x[1].split()\n",
    "    text.append('\\n')\n",
    "    matrix = np.zeros((300,), dtype = 'float32')\n",
    "    for word in text:\n",
    "        matrix += div_norm(fast_text.word_vec(word))\n",
    "    vacancy_vectors[x[0]] = matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"python git data science machine learning\"\n",
    "text = \"сми репутация сторителлинг фактчекинг пресс-релиз коммуникация pr журналист москва\"\n",
    "text = text.split()\n",
    "text.append('\\n')\n",
    "matrix = np.zeros((300,), dtype = 'float32')\n",
    "for word in text:\n",
    "    matrix += div_norm(fast_text.word_vec(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tu_sims = {}\n",
    "for vacid in tqdm(vacids):\n",
    "    tu_sims[vacid] = cosine_similarity(vacancy_vectors[vacid].reshape(1,-1),\n",
    "                                       matrix.reshape(1,-1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu_sorted = sorted(tu_sims.items(), key=lambda x:x[1], reverse=True)\n",
    "tu_sorted = [x[0] for x in tu_sorted]\n",
    "df = pd.DataFrame({'description':lines, 'vacid':vacids})\n",
    "df = df.set_index('vacid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[tu_sorted[]].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "unpickling stack underflow",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnpicklingError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-dc54bced2869>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m# Load pre-trained Word2Vec model.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mmodelpth\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'..'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m'wvmodel'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m'182'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m'model.bin'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgensim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mWord2Vec\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodelpth\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/app-sberjobs/sberjobs-trainer/venv/lib/python3.8/site-packages/gensim/models/word2vec.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1139\u001B[0m         \"\"\"\n\u001B[1;32m   1140\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1141\u001B[0;31m             \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mWord2Vec\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1142\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1143\u001B[0m             \u001B[0;31m# for backward compatibility for `max_final_vocab` feature\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/app-sberjobs/sberjobs-trainer/venv/lib/python3.8/site-packages/gensim/models/base_any2vec.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1228\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1229\u001B[0m         \"\"\"\n\u001B[0;32m-> 1230\u001B[0;31m         \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mBaseWordEmbeddingsModel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1231\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'ns_exponent'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1232\u001B[0m             \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mns_exponent\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0.75\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/app-sberjobs/sberjobs-trainer/venv/lib/python3.8/site-packages/gensim/models/base_any2vec.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(cls, fname_or_handle, **kwargs)\u001B[0m\n\u001B[1;32m    600\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    601\u001B[0m         \"\"\"\n\u001B[0;32m--> 602\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mBaseAny2VecModel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfname_or_handle\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    603\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    604\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfname_or_handle\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/app-sberjobs/sberjobs-trainer/venv/lib/python3.8/site-packages/gensim/utils.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(cls, fname, mmap)\u001B[0m\n\u001B[1;32m    433\u001B[0m         \u001B[0mcompress\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msubname\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mSaveLoad\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_adapt_by_suffix\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    434\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 435\u001B[0;31m         \u001B[0mobj\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0munpickle\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    436\u001B[0m         \u001B[0mobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_load_specials\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmmap\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcompress\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msubname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    437\u001B[0m         \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"loaded %s\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/app-sberjobs/sberjobs-trainer/venv/lib/python3.8/site-packages/gensim/utils.py\u001B[0m in \u001B[0;36munpickle\u001B[0;34m(fname)\u001B[0m\n\u001B[1;32m   1396\u001B[0m         \u001B[0;31m# Because of loading from S3 load can't be used (missing readline in smart_open)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1397\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0msys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mversion_info\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1398\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0m_pickle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'latin1'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1399\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1400\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0m_pickle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloads\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mUnpicklingError\u001B[0m: unpickling stack underflow"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gensim\n",
    "\n",
    "# Load pre-trained Word2Vec model.\n",
    "modelpth = os.path.join('..','wvmodel','182','model.bin')\n",
    "model = gensim.models.Word2Vec.load(modelpth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "modelpth = \"ruwikiruscorpora_0_300_20.bin.gz\"\n",
    "modelpth = os.path.join('..','wvmodel','182','model.bin')\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(modelpth, binary=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unable to read local cache '/Users/lev4/gensim-data/information.json' during fallback, connect to the Internet and retry",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m~/PycharmProjects/app-sberjobs/sberjobs-trainer/venv/lib/python3.8/site-packages/gensim/downloader.py\u001B[0m in \u001B[0;36m_load_info\u001B[0;34m(url, encoding)\u001B[0m\n\u001B[1;32m    217\u001B[0m         \u001B[0;31m#\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 218\u001B[0;31m         \u001B[0;32mwith\u001B[0m \u001B[0mio\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcache_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'r'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mencoding\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mfin\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    219\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mjson\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfin\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/Users/lev4/gensim-data/information.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-79084782ef88>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mwv\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mapi\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'word2vec-ruscorpora-300'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/app-sberjobs/sberjobs-trainer/venv/lib/python3.8/site-packages/gensim/downloader.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(name, return_path)\u001B[0m\n\u001B[1;32m    487\u001B[0m     \"\"\"\n\u001B[1;32m    488\u001B[0m     \u001B[0m_create_base_dir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 489\u001B[0;31m     \u001B[0mfile_name\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_get_filename\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    490\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mfile_name\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    491\u001B[0m         \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Incorrect model/corpus name\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/app-sberjobs/sberjobs-trainer/venv/lib/python3.8/site-packages/gensim/downloader.py\u001B[0m in \u001B[0;36m_get_filename\u001B[0;34m(name)\u001B[0m\n\u001B[1;32m    423\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    424\u001B[0m     \"\"\"\n\u001B[0;32m--> 425\u001B[0;31m     \u001B[0minformation\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    426\u001B[0m     \u001B[0mcorpora\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minformation\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'corpora'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    427\u001B[0m     \u001B[0mmodels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minformation\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'models'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/app-sberjobs/sberjobs-trainer/venv/lib/python3.8/site-packages/gensim/downloader.py\u001B[0m in \u001B[0;36minfo\u001B[0;34m(name, show_only_latest, name_only)\u001B[0m\n\u001B[1;32m    265\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    266\u001B[0m     \"\"\"\n\u001B[0;32m--> 267\u001B[0;31m     \u001B[0minformation\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_load_info\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    268\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    269\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/app-sberjobs/sberjobs-trainer/venv/lib/python3.8/site-packages/gensim/downloader.py\u001B[0m in \u001B[0;36m_load_info\u001B[0;34m(url, encoding)\u001B[0m\n\u001B[1;32m    219\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mjson\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfin\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    220\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mIOError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 221\u001B[0;31m         raise ValueError(\n\u001B[0m\u001B[1;32m    222\u001B[0m             \u001B[0;34m'unable to read local cache %r during fallback, '\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    223\u001B[0m             \u001B[0;34m'connect to the Internet and retry'\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mcache_path\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: unable to read local cache '/Users/lev4/gensim-data/information.json' during fallback, connect to the Internet and retry"
     ]
    }
   ],
   "source": [
    "wv = api.load('word2vec-ruscorpora-300')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unable to read local cache '/Users/lev4/gensim-data/information.json' during fallback, connect to the Internet and retry",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m~/PycharmProjects/app-sberjobs/sberjobs-trainer/venv/lib/python3.8/site-packages/gensim/downloader.py\u001B[0m in \u001B[0;36m_load_info\u001B[0;34m(url, encoding)\u001B[0m\n\u001B[1;32m    217\u001B[0m         \u001B[0;31m#\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 218\u001B[0;31m         \u001B[0;32mwith\u001B[0m \u001B[0mio\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcache_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'r'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mencoding\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mfin\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    219\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mjson\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfin\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/Users/lev4/gensim-data/information.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-4f2eb48c35c9>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mapi\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'glove-wiki-gigaword-50'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/app-sberjobs/sberjobs-trainer/venv/lib/python3.8/site-packages/gensim/downloader.py\u001B[0m in \u001B[0;36minfo\u001B[0;34m(name, show_only_latest, name_only)\u001B[0m\n\u001B[1;32m    265\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    266\u001B[0m     \"\"\"\n\u001B[0;32m--> 267\u001B[0;31m     \u001B[0minformation\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_load_info\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    268\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    269\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/app-sberjobs/sberjobs-trainer/venv/lib/python3.8/site-packages/gensim/downloader.py\u001B[0m in \u001B[0;36m_load_info\u001B[0;34m(url, encoding)\u001B[0m\n\u001B[1;32m    219\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mjson\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfin\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    220\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mIOError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 221\u001B[0;31m         raise ValueError(\n\u001B[0m\u001B[1;32m    222\u001B[0m             \u001B[0;34m'unable to read local cache %r during fallback, '\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    223\u001B[0m             \u001B[0;34m'connect to the Internet and retry'\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mcache_path\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: unable to read local cache '/Users/lev4/gensim-data/information.json' during fallback, connect to the Internet and retry"
     ]
    }
   ],
   "source": [
    "api.info('glove-wiki-gigaword-50')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}