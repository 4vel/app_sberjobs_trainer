{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tqdm\n",
    "import pymorphy2\n",
    "import logging\n",
    "import os\n",
    "from string import punctuation\n",
    "from nltk import TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm.auto import tqdm\n",
    "from sqlalchemy import create_engine\n",
    "from src.config import conn_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "logging.basicConfig(level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines(conn_string):\n",
    "    \"\"\"\n",
    "    Подключается к БД и выкачивает вакансии\n",
    "    \"\"\"\n",
    "    logging.info(\"Подгружаю данные из базы\")\n",
    "    engine = create_engine(conn_string)\n",
    "\n",
    "    df = pd.read_sql_table('vacancy', engine)\n",
    "    logging.info(df.head)\n",
    "    lines = df.vacdescription.tolist()\n",
    "    vacids = df.vacid.tolist()\n",
    "    return lines, vacids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_pipe(lines):\n",
    "    logging.info(\"Готовлю корпус\")\n",
    "    ru_stop_words = stopwords.words('russian')\n",
    "    lines_tok = [TreebankWordTokenizer().tokenize(x) for x in lines]\n",
    "    lines_tok = [[x for x in el if x not in punctuation] for el in lines_tok]\n",
    "    u_norm = [[morph.parse(x)[0][2] for x in el] for el in tqdm(lines_tok)]\n",
    "    u_norm = [[x for x in el if x not in ru_stop_words] for el in tqdm(u_norm)]\n",
    "    corpus = [' '.join(x) for x in u_norm]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def l2_norm(x):\n",
    "    return np.sqrt(np.sum(x ** 2))\n",
    "\n",
    "\n",
    "def div_norm(x):\n",
    "    norm_value = l2_norm(x)\n",
    "    if norm_value > 0:\n",
    "        return x * (1.0 / norm_value)\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vacancy_vectors(vacids, corpus):\n",
    "    \"\"\"\n",
    "    Получает вектора профилей пользователей из фасттекста\n",
    "    \"\"\"\n",
    "\n",
    "    from gensim.models import FastText\n",
    "    \n",
    "    vacancy_vectors = {}\n",
    "    logging.info(\"Подгружаем обученную модель FastText\")\n",
    "    fasttext_pth = os.path.join('..','wvmodel','cc.ru.300.bin')\n",
    "    fast_text = FastText.load_fasttext_format(fasttext_pth).wv\n",
    "    \n",
    "    logging.info(\"Собираем векторы предложений\")\n",
    "    for x in tqdm((vacids, corpus)):\n",
    "\n",
    "        text = x[1].split()\n",
    "        text.append('\\n')\n",
    "        matrix = np.zeros((300,), dtype = 'float32')\n",
    "\n",
    "        for word in text:\n",
    "            matrix += div_norm(fast_text.word_vec(word))\n",
    "\n",
    "        vacancy_vectors[x[0]] = matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_similarities(target_user, candidates):\n",
    "    \"\"\"Получает косинусные сходства сотрудника и кандидатов\"\"\"\n",
    "\n",
    "    tu_sims = {}\n",
    "    for vacid in vacids:\n",
    "        tu_sims[candidates] = cosine_similarity(\n",
    "            vacancy_vectors[vacid],\n",
    "            user_vectors\n",
    "        )[0][0]\n",
    "\n",
    "    return tu_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Подгружаю данные из базы\n",
      "INFO:root:<bound method NDFrame.head of           id                 created_at                 updated_at   vacid  \\\n",
      "0     416760 2020-12-17 20:17:18.625748 2020-12-17 20:17:18.625881   85441   \n",
      "1     416761 2020-12-17 20:17:18.625748 2020-12-17 20:17:18.625881   99242   \n",
      "2     416762 2020-12-17 20:17:18.625748 2020-12-17 20:17:18.625881  101976   \n",
      "3     416763 2020-12-17 20:17:18.625748 2020-12-17 20:17:18.625881  101988   \n",
      "4     416764 2020-12-17 20:17:18.625748 2020-12-17 20:17:18.625881  392309   \n",
      "...      ...                        ...                        ...     ...   \n",
      "3408  420168 2020-12-17 20:17:18.625748 2020-12-17 20:17:18.625881  696912   \n",
      "3409  420169 2020-12-17 20:17:18.625748 2020-12-17 20:17:18.625881  701151   \n",
      "3410  420170 2020-12-17 20:17:18.625748 2020-12-17 20:17:18.625881  706219   \n",
      "3411  420171 2020-12-17 20:17:18.625748 2020-12-17 20:17:18.625881  706232   \n",
      "3412  420172 2020-12-17 20:17:18.625748 2020-12-17 20:17:18.625881  706241   \n",
      "\n",
      "                            vactitle  \\\n",
      "0     Мобильный менеджер по продажам   \n",
      "1     Мобильный менеджер по продажам   \n",
      "2     Мобильный менеджер по продажам   \n",
      "3     Мобильный менеджер по продажам   \n",
      "4      Специалист по прямым продажам   \n",
      "...                              ...   \n",
      "3408             Лучший по профессии   \n",
      "3409            Менеджер по продажам   \n",
      "3410            Менеджер по продажам   \n",
      "3411            Менеджер по продажам   \n",
      "3412            Менеджер по продажам   \n",
      "\n",
      "                                         vacdescription     vacdate vacstatus  \\\n",
      "0     Мы предлагаем:оформление согласно трудовому ко...  2020-12-22       new   \n",
      "1     Мы предлагаем: - оформление согласно трудовому...  2020-12-22       new   \n",
      "2     Мы предлагаем: - оформление согласно трудовому...  2020-12-22       new   \n",
      "3     Мы предлагаем:- оформление согласно трудовому ...  2020-12-22       new   \n",
      "4     Мы предлагаем:  трудоустройство согласно ТК РФ...  2020-12-22       new   \n",
      "...                                                 ...         ...       ...   \n",
      "3408                                                     2019-07-19       new   \n",
      "3409  Мы предлагаем: трудоустройство согласно ТК РФ;...  2019-07-22       new   \n",
      "3410  Если ты: ·         хочешь построить карьеру в ...  2019-07-26       new   \n",
      "3411  от 35000 до вычета налогов Если ты: ·         ...  2019-07-26       new   \n",
      "3412  Если ты: ·         хочешь построить карьеру в ...  2019-07-26       new   \n",
      "\n",
      "                                                vaclink  \n",
      "0     https://my.sbertalents.ru/#/job-requisition/85441  \n",
      "1     https://my.sbertalents.ru/#/job-requisition/99242  \n",
      "2     https://my.sbertalents.ru/#/job-requisition/10...  \n",
      "3     https://my.sbertalents.ru/#/job-requisition/10...  \n",
      "4     https://my.sbertalents.ru/#/job-requisition/39...  \n",
      "...                                                 ...  \n",
      "3408  https://my.sbertalents.ru/#/job-requisition/69...  \n",
      "3409  https://my.sbertalents.ru/#/job-requisition/70...  \n",
      "3410  https://my.sbertalents.ru/#/job-requisition/70...  \n",
      "3411  https://my.sbertalents.ru/#/job-requisition/70...  \n",
      "3412  https://my.sbertalents.ru/#/job-requisition/70...  \n",
      "\n",
      "[3413 rows x 9 columns]>\n"
     ]
    }
   ],
   "source": [
    "lines, vacids = get_lines(conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Готовлю корпус\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cefca5d8ee84a32a4f53a4237ac6ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3413.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6de39385814f50832b3cd3e14b58ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3413.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corpus = txt_pipe(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with open(os.path.join('..','data','corpus.pkl'), 'wb') as f:\n",
    "#     pickle.dump(corpus, f)\n",
    "\n",
    "# with open(os.path.join('..','data','vacids.pkl'), 'wb') as f:\n",
    "#     pickle.dump(vacids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/vacids.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-92eb2f2afadb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'..'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'vacids.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mvacids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'..'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'corpus.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/vacids.pkl'"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('..','data','vacids.pkl'), 'rb') as f:\n",
    "    vacids = pickle.load(f)\n",
    "\n",
    "with open(os.path.join('..','data','corpus.pkl'), 'rb') as f:\n",
    "    corpus = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Подгружаем обученную модель FastText\n",
      "<ipython-input-6-f11b5deadedb>:11: DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead).\n",
      "  fast_text = FastText.load_fasttext_format(fasttext_pth).wv\n",
      "INFO:gensim.models._fasttext_bin:loading 1888423 words for fastText model from ../wvmodel/cc.ru.300.bin\n",
      "INFO:gensim.models.word2vec:resetting layer weights\n",
      "INFO:gensim.models.word2vec:Updating model with new vocabulary\n",
      "INFO:gensim.models.word2vec:New added 1888423 unique words (50% of original 3776846) and increased the count of 1888423 pre-existing words (50% of original 3776846)\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 1888423 items\n",
      "INFO:gensim.models.word2vec:sample=0.0001 downsamples 510 most-common words\n",
      "INFO:gensim.models.word2vec:downsampling leaves estimated 968832418 word corpus (120.5% of prior 803768482)\n",
      "INFO:gensim.models.fasttext:loaded (3888423, 300) weight matrix for fastText model from ../wvmodel/cc.ru.300.bin\n",
      "INFO:root:Собираем векторы предложений\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8fa50a1a5e74f0f9fd5234ac1140b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vvect = get_vacancy_vectors(vacids, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_vector(user_text):\n",
    "    \"\"\" Формирует вектор из ключевых слов пользователя \"\"\"\n",
    "    from gensim.models import FastText\n",
    "    \n",
    "\n",
    "    logging.info(\"Подгружаем обученную модель FastText\")\n",
    "    fasttext_pth = os.path.join('..','wvmodel','cc.ru.300.bin')\n",
    "    fast_text = FastText.load_fasttext_format(fasttext_pth).wv\n",
    "    \n",
    "    logging.info(\"Собираем векторы предложений\")\n",
    "\n",
    "    user_text = user_text.split()\n",
    "    user_text.append('\\n')\n",
    "    matrix = np.zeros((300,), dtype = 'float32')\n",
    "\n",
    "    for word in user_text:\n",
    "        matrix += div_norm(fast_text.word_vec(word))\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_text_vectors(user_txt_dict):\n",
    "    \"\"\" Формирует векторы для всех пользователей и записывает в словарь \"\"\"\n",
    "\n",
    "    user_text_vectors = {}\n",
    "    for user_id, keywords in user_txt_dict.items():\n",
    "        user_text_vectors[user_id] = get_text_vector(keywords)\n",
    "\n",
    "    return user_text_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Подгружаем обученную модель FastText\n",
      "<ipython-input-21-8ec01e22a297>:8: DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead).\n",
      "  fast_text = FastText.load_fasttext_format(fasttext_pth).wv\n",
      "INFO:gensim.models._fasttext_bin:loading 1888423 words for fastText model from ../wvmodel/cc.ru.300.bin\n",
      "INFO:gensim.models.word2vec:resetting layer weights\n",
      "INFO:gensim.models.word2vec:Updating model with new vocabulary\n",
      "INFO:gensim.models.word2vec:New added 1888423 unique words (50% of original 3776846) and increased the count of 1888423 pre-existing words (50% of original 3776846)\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 1888423 items\n",
      "INFO:gensim.models.word2vec:sample=0.0001 downsamples 510 most-common words\n",
      "INFO:gensim.models.word2vec:downsampling leaves estimated 968832418 word corpus (120.5% of prior 803768482)\n",
      "INFO:gensim.models.fasttext:loaded (3888423, 300) weight matrix for fastText model from ../wvmodel/cc.ru.300.bin\n",
      "INFO:root:Собираем векторы предложений\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: array([-4.40742821e-04,  9.24402326e-02,  1.38517320e-01, -7.05969989e-01,\n",
       "         1.31782681e-01, -1.12261623e-02,  2.37889171e-01, -2.52624154e-01,\n",
       "         3.19628924e-01,  3.96308228e-02, -1.35322995e-02, -7.23003745e-02,\n",
       "         4.29560453e-01,  2.28546590e-01,  6.69134259e-02, -2.19147444e-01,\n",
       "        -8.80413875e-03, -3.29314351e-01,  6.20986879e-01,  2.24975705e-01,\n",
       "         3.55819836e-02,  2.15868458e-01, -3.26183915e-01, -4.68632907e-01,\n",
       "        -7.29218796e-02, -1.01908818e-01, -2.23477464e-02,  7.76955411e-02,\n",
       "        -4.04997647e-01,  2.16299593e-02,  1.23945780e-01, -8.45732167e-02,\n",
       "         2.79955894e-01,  1.68110784e-02,  4.45793085e-02,  1.52397349e-01,\n",
       "         1.25535414e-01, -2.32889101e-01,  1.98648259e-01,  1.75265267e-01,\n",
       "        -1.39682949e-01,  1.19266458e-01, -2.35276148e-02,  1.89557001e-01,\n",
       "         8.03967044e-02,  6.04265742e-02,  1.12643361e-01,  6.19361550e-02,\n",
       "        -7.17460215e-02,  2.55582482e-03,  1.69044033e-01,  7.41387308e-02,\n",
       "         2.73848474e-01,  8.03299621e-02,  3.03739488e-01,  1.38236344e-01,\n",
       "        -1.00218326e-01,  2.30614156e-01,  2.25339726e-01,  2.11307392e-01,\n",
       "         7.27814361e-02, -3.00192125e-02, -2.05553830e-01, -9.27629322e-03,\n",
       "        -6.39977306e-03,  3.88069183e-01, -5.93503416e-01, -1.28906220e-01,\n",
       "         3.68959665e-01, -2.51454324e-01,  4.85073984e-01,  2.62960017e-01,\n",
       "        -2.37577349e-01, -2.08492652e-02, -2.98415840e-01, -1.97508603e-01,\n",
       "        -2.34333277e-02, -5.14971539e-02,  1.27013266e-01, -5.25406361e-01,\n",
       "         7.67888576e-02,  2.06841007e-02,  2.71223843e-01,  2.65052803e-02,\n",
       "         3.70128542e-01,  2.46290583e-02,  1.26937672e-01,  4.35526818e-01,\n",
       "        -2.01398417e-01, -4.65439975e-01, -7.37106130e-02, -1.77526534e-01,\n",
       "        -1.73560739e-01, -8.59572887e-02, -2.13350102e-01, -2.13834018e-01,\n",
       "         2.41887420e-01,  3.84109288e-01, -2.20603168e-01, -5.10163486e-01,\n",
       "         1.65952235e-01,  5.54475009e-01,  3.50289404e-01, -3.28233123e-01,\n",
       "         3.04238558e-01,  3.78981322e-01,  2.25889951e-01, -1.98949188e-01,\n",
       "         1.65199488e-01,  2.16553420e-01,  2.24937707e-01, -1.21002942e-01,\n",
       "        -5.60359210e-02,  4.16293383e-01, -4.12697315e-01,  2.62601346e-01,\n",
       "         1.11842930e-01,  1.02761686e-01, -1.70584425e-01,  4.36281115e-01,\n",
       "        -3.85205895e-02, -2.75457697e-03,  6.56220913e-02, -3.37161779e-01,\n",
       "         4.99017924e-01, -3.58119726e-01,  4.84603405e-01,  3.50270599e-01,\n",
       "         5.76431490e-02,  1.62421823e-01,  6.04611814e-01,  1.67920440e-02,\n",
       "        -4.18332845e-01, -4.24049616e-01,  2.83042371e-01,  2.94915974e-01,\n",
       "        -3.02332968e-01, -3.79154325e-01,  1.52184933e-01,  4.79475796e-01,\n",
       "        -5.17790735e-01, -4.47854459e-01,  3.43625873e-01,  1.41495243e-01,\n",
       "         1.74630120e-01, -3.17082584e-01, -2.63775229e-01,  1.58557937e-01,\n",
       "         1.41999558e-01, -9.78146717e-02, -3.93775225e-01, -5.65641463e-01,\n",
       "         4.50041071e-02, -5.10689244e-03, -4.48183179e-01,  8.51223469e-02,\n",
       "        -5.54706827e-02,  1.01393878e-01,  4.42719996e-01,  3.54942530e-01,\n",
       "        -4.15465772e-01,  2.31313527e-01, -2.44479328e-01, -1.27343670e-01,\n",
       "        -1.91399753e-01,  1.30147859e-03,  2.27629855e-01, -1.35694280e-01,\n",
       "        -2.39205882e-01,  1.80432945e-01, -1.89437836e-01,  1.88358687e-02,\n",
       "        -2.62769312e-01,  2.63516337e-01,  2.59662330e-01, -4.76208925e-01,\n",
       "        -1.04256541e-01, -3.17481697e-01, -6.94680884e-02,  2.18780130e-01,\n",
       "        -2.48423800e-01,  1.01157323e-01, -9.81920213e-02,  9.24329683e-02,\n",
       "         3.40575352e-03, -3.30073118e-01, -7.76391178e-02, -2.13822439e-01,\n",
       "         2.75773406e-01,  3.36921588e-02, -4.62787598e-01, -2.99903423e-01,\n",
       "         3.95054132e-01, -1.44441038e-01, -1.64742917e-01, -3.03264469e-01,\n",
       "        -2.07887337e-01,  4.22352701e-02, -1.35742262e-01,  1.69344053e-01,\n",
       "        -1.11146837e-01,  9.63012576e-02,  1.38349786e-01, -1.57692283e-01,\n",
       "         2.71246076e-01, -1.47904048e-03,  2.97643781e-01,  2.94851929e-01,\n",
       "        -1.19256526e-01,  4.97047305e-01, -1.67468060e-02, -2.16978654e-01,\n",
       "        -1.50161654e-01, -2.95627773e-01, -2.33809590e-01, -2.16577351e-01,\n",
       "        -2.05986544e-01, -2.19093814e-01, -6.70036376e-02, -9.19022113e-02,\n",
       "         6.55148029e-02,  1.77474841e-01,  7.09598288e-02,  7.97262490e-02,\n",
       "        -3.30535173e-01,  1.81560442e-01, -2.39427155e-03, -7.86270797e-02,\n",
       "        -1.01867519e-01,  7.44026750e-02,  1.70923114e-01,  4.97206420e-01,\n",
       "         2.17278361e-01, -1.05517611e-01,  3.65559757e-02, -2.73346364e-01,\n",
       "         9.99987032e-03,  5.93113899e-03, -1.85475573e-01,  3.06503564e-01,\n",
       "        -3.21325868e-01,  6.85132220e-02,  1.01861738e-01,  2.78215349e-01,\n",
       "         6.26689553e-01, -9.88955870e-02,  4.72939163e-01,  2.44148225e-01,\n",
       "         2.46488079e-02,  7.61003941e-02,  1.37405783e-01,  4.50261608e-02,\n",
       "        -3.59863460e-01,  3.83475929e-01, -2.92095035e-01,  2.26077586e-02,\n",
       "         1.04114324e-01,  2.68561572e-01, -1.63114145e-01,  1.52045667e-01,\n",
       "         1.22028485e-01, -5.71787953e-01,  1.99871942e-01,  2.99486935e-01,\n",
       "        -5.24434268e-01, -1.81613803e-01,  1.51585072e-01, -3.98811549e-01,\n",
       "         3.17421377e-01, -1.86357349e-01,  1.55404449e-01, -2.67029583e-01,\n",
       "         1.37606651e-01, -1.24335282e-01, -1.11307338e-01, -2.22876161e-01,\n",
       "         3.36254686e-02,  1.36472210e-01,  1.40737593e-01,  3.95578772e-01,\n",
       "         2.54465997e-01,  2.70993054e-01,  1.82630599e-01,  1.42100960e-01,\n",
       "         4.82022822e-01,  1.93401963e-01,  5.95320426e-02, -1.86119422e-01,\n",
       "        -1.82122916e-01, -1.49698034e-01,  1.71935797e-01,  6.11694828e-02,\n",
       "        -4.31897461e-01, -1.79900080e-01,  2.64501959e-01, -1.64969325e-01,\n",
       "         1.41712680e-01,  9.42045376e-02,  1.12164438e-01, -9.60121900e-02],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"python git data science machine learning\"\n",
    "text = {1:text}\n",
    "get_user_text_vectors(text,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# with open(os.path.join('..','data','fast_text.pkl'), 'wb') as f:\n",
    "#     pickle.dump(fast_text, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacancy_vectors = {}\n",
    "for x in tqdm(list(zip(vacids, corpus))):\n",
    "    text = x[1].split()\n",
    "    text.append('\\n')\n",
    "    matrix = np.zeros((300,), dtype = 'float32')\n",
    "    for word in text:\n",
    "        matrix += div_norm(fast_text.word_vec(word))\n",
    "    vacancy_vectors[x[0]] = matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"python git data science machine learning\"\n",
    "text = \"сми репутация сторителлинг фактчекинг пресс-релиз коммуникация pr журналист москва\"\n",
    "text = text.split()\n",
    "text.append('\\n')\n",
    "matrix = np.zeros((300,), dtype = 'float32')\n",
    "for word in text:\n",
    "    matrix += div_norm(fast_text.word_vec(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tu_sims = {}\n",
    "for vacid in tqdm(vacids):\n",
    "    tu_sims[vacid] = cosine_similarity(vacancy_vectors[vacid].reshape(1,-1),\n",
    "                                       matrix.reshape(1,-1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu_sorted = sorted(tu_sims.items(), key=lambda x:x[1], reverse=True)\n",
    "tu_sorted = [x[0] for x in tu_sorted]\n",
    "df = pd.DataFrame({'description':lines, 'vacid':vacids})\n",
    "df = df.set_index('vacid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[tu_sorted[]].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
